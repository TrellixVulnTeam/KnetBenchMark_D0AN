{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define hyper-parameters\n",
    "const EPOCHS=3\n",
    "const BATCHSIZE=64\n",
    "const EMBEDSIZE=125\n",
    "const NUMHIDDEN=100\n",
    "const DROPOUT=0.2\n",
    "const LR=0.001\n",
    "const BETA_1=0.9\n",
    "const BETA_2=0.999\n",
    "const EPS=1e-08\n",
    "const MAXLEN=150 #maximum size of the word sequence\n",
    "const MAXFEATURES=30000 #vocabulary size\n",
    "const outlabel=2 #output label in sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mPrecompiling module ArgParse.\n",
      "\u001b[39m"
     ]
    }
   ],
   "source": [
    "using Knet, JLD, ArgParse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f (generic function with 2 methods)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helper methods for prepocessing file\n",
    "f(x::AbstractString, y::AbstractString) = map(x->convert(Int, x), readdlm(\"$y/$x\"))\n",
    "nz(t) = sum(t .== 0)\n",
    "f(x::Int) = (x==0 ? 2 : x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "imdb_for_library (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 0 indexing Python arrays to 1 indexing Julia Arrays\n",
    "function correct_data(data::Array)\n",
    "    x_correct = fill!(similar(data), 0)\n",
    "    for i in 1:size(data)[1]\n",
    "        nzeros = nz(data[i,:])\n",
    "        x_correct[i, nzeros+1:end] = data[i, 1:end-nzeros]\n",
    "    end\n",
    "    return x_correct\n",
    "end\n",
    "\n",
    "# Retrieve training and test data\n",
    "function imdb_for_library(;datadir=\"RNN\")\n",
    "    x_train = correct_data(f(\"x_train.txt\", datadir))\n",
    "    y_train = f(\"y_train.txt\", datadir)\n",
    "    info(\"Train data loaded\")\n",
    "    info(\"Test data loaded\")\n",
    "    x_test = correct_data(f(\"x_test.txt\", datadir))\n",
    "    y_test = f(\"y_test.txt\", datadir)\n",
    "    return (x_train, x_test, y_train, y_test)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "minibatch (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function minibatch(corpus, labels, batchsize)\n",
    "    data, ygolds = Any[], Any[]\n",
    "    indix = randperm(length(labels))\n",
    "    for i in 1:batchsize:size(corpus)[1]\n",
    "        j = min(i+batchsize-1, size(corpus)[1]) # To find surplus data\n",
    "        batch = corpus[indix[i:j], :]\n",
    "        push!(ygolds, labels[indix[i:j]])\n",
    "        sequences = Any[]\n",
    "        for r in 1:size(batch)[2]\n",
    "            s1 = map(f, batch[:, r])\n",
    "            push!(sequences, s1)\n",
    "        end\n",
    "        push!(data, sequences)\n",
    "    end\n",
    "    return data, ygolds\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "initmodel (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function initmodel(embed_size, hidden_size, vocab_size, outsize; init=randn, ftype=Float32)\n",
    "    model = Any[]\n",
    "    f = (gpu()>=0 ? KnetArray{ftype} : Array{ftype})\n",
    "    c = (init == randn ? 0.1 : 1)\n",
    "    compound_init(x...) = f(c*init(x...))\n",
    "    push!(model, compound_init(embed_size, vocab_size)) # embedding\n",
    "    push!(model, compound_init(outsize, hidden_size)) # soft_w\n",
    "    push!(model, f(zeros(outsize, 1))) # soft_b\n",
    "    push!(model, compound_init(2hidden_size, hidden_size+embed_size)) # gru_w1\n",
    "    push!(model, compound_init(hidden_size, hidden_size+embed_size)) # gru_w2\n",
    "    return model\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRU_w2 (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#implement accessors\n",
    "embed(model) = model[1]\n",
    "soft_w(model) = model[2]\n",
    "soft_b(model) = model[3]\n",
    "GRU_w1(model) = model[4]\n",
    "GRU_w2(model) = model[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gru (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column based GRU\n",
    "function gru(weight1, weight2, hidden, input)\n",
    "    gates = sigm.(weight1*vcat(input, hidden))\n",
    "    H = size(hidden, 1)\n",
    "    z = gates[1:H, :]\n",
    "    r = gates[1+H:2H, :]\n",
    "    change = tanh.(weight2 * vcat(r .* hidden, input))\n",
    "    hidden = (1 .- z) .* hidden + z .* change\n",
    "    return hidden\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forward (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function forward(model, hidden, sequence)\n",
    "    embedding, gru_w1, gru_w2  = embed(model), GRU_w1(model), GRU_w2(model)\n",
    "    soft_W, soft_B = soft_w(model), soft_b(model)\n",
    "    for idx in sequence\n",
    "        input = embedding[:, idx]\n",
    "        hidden = gru(gru_w1, gru_w2, hidden, input)\n",
    "    end\n",
    "    ypred = soft_W * hidden .+ soft_B  \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logprob (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To calculate the correct log-probabilities for given set of outputs\n",
    "function logprob(outputs, ypred)\n",
    "    nrows, _ = size(ypred)\n",
    "    index = similar(outputs)\n",
    "    @inbounds for i in 1:length(outputs)\n",
    "        index[i] = (outputs[i]+1) + (i-1)*nrows\n",
    "    end\n",
    "    o1 = logp(ypred, 1)\n",
    "    o2 = o1[index]\n",
    "    o3 = sum(o2)\n",
    "    return o3\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gruloss (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gruloss(model, state, sequence, ygold)\n",
    "    hidden = zeros(similar(state[1], size(state[1])[1], length(ygold)))\n",
    "    ypred = forward(model, hidden, sequence)\n",
    "    total = logprob(ygold, ypred)\n",
    "    count = length(ygold)\n",
    "    val =  -total / count\n",
    "    return val\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(::gradfun) (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grugrad = grad(gruloss) # Knet takes care of grads :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "oparams (generic function with 4 methods)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimization parameter initializer for each parameter of the model\n",
    "oparams{T<:Number}(::KnetArray{T},otype; o...)=otype(;o...)\n",
    "oparams{T<:Number}(::Array{T},otype; o...)=otype(;o...)\n",
    "oparams(a::Associative,otype; o...)=Dict([k=>oparams(v,otype;o...) for (k,v) in a])\n",
    "oparams(a,otype; o...)=map(x->oparams(x,otype;o...), a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To calculate the accuracies for given test set\n",
    "function accuracy(model, xtest, ytest)\n",
    "    atype = (gpu()>=0 ? KnetArray{Float32} : Array{Float32})\n",
    "    ntot = 0; ncorrect = 0\n",
    "    batchsize= BATCHSIZE\n",
    "    data, ygolds = minibatch(xtest, ytest, BATCHSIZE)\n",
    "    hidden_size = NUMHIDDEN\n",
    "    for (sequence, ygold) in zip(data, ygolds)\n",
    "        hidden = atype(zeros(Float32, hidden_size, length(ygold)))\n",
    "        ypred = forward(model, hidden, sequence)\n",
    "        nrows, _ = size(ypred)\n",
    "        index = similar(ygold)\n",
    "        @inbounds for i in 1:length(ygold)\n",
    "            index[i] = (ygold[i]+1) + (i-1)*nrows\n",
    "        end\n",
    "        ntot += length(index)\n",
    "        ncorrect += (sum(reshape(findmax(Array((logp(ypred, 1))), 1)[2], length(ygold)) .== index))\n",
    "    end\n",
    "    return ncorrect/ntot\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main (generic function with 2 methods)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function main(args=ARGS)\n",
    "    s = ArgParseSettings()\n",
    "    s.description = \"Knet GRU based sentiment analysis model\"\n",
    "    s.exc_handler = ArgParse.debug_handler\n",
    "    @add_arg_table s begin\n",
    "        (\"--epochs\"; arg_type=Int; default=3; help=\"Number of training epochs\")\n",
    "        (\"--optimization\"; default=\"Adam\"; help=\"Optimization algorithm\")\n",
    "        (\"--hidden\"; arg_type=Int; default=NUMHIDDEN; help=\"Number of GRU hidden units\")\n",
    "        (\"--embed\"; arg_type=Int; default=EMBEDSIZE; help=\"Number of embedding units\")\n",
    "        (\"--batchsize\"; arg_type=Int; default=BATCHSIZE; help=\"Batchsize of model\")\n",
    "        (\"--lr\"; arg_type=Float64; default=LR; help=\"Learning rate\")\n",
    "        (\"--betas\"; nargs='+'; default=[BETA_1, BETA_2]; help=\"Beta parameters of ADAM\")\n",
    "        (\"--eps\"; arg_type=Float64; default=EPS; help=\"Epsilon parameter of ADAM\")\n",
    "        (\"--maxfeatures\"; arg_type=Int; default=MAXFEATURES; help=\"Padded sequence length\")\n",
    "    end\n",
    "    isa(args, AbstractString) && (args=split(args))\n",
    "    o = parse_args(args, s; as_symbols=true)\n",
    "    println(s.description)\n",
    "    inoptim = eval(parse(o[:optimization]))\n",
    "    println(\"opts=\", [(k,v) for (k,v) in o]...)\n",
    "\n",
    "    atype = (gpu()>=0 ? KnetArray : Array)\n",
    "\n",
    "    info(\"reading the data...\")\n",
    "    x_train, x_test, y_train, y_test = imdb_for_library();\n",
    "    odata, ygolds = minibatch(x_train, y_train, o[:batchsize])\n",
    "\n",
    "    info(\"Initializing the model\")\n",
    "    model = initmodel(o[:embed], o[:hidden], o[:maxfeatures], outlabel)\n",
    "    state = Any[ atype(zeros(Float32, o[:hidden], o[:batchsize])) ]\n",
    "\n",
    "    opts = oparams(model, inoptim;lr=o[:lr], beta1=o[:betas][1], beta2=o[:betas][2], eps=o[:eps])\n",
    "    info(\"Calculating the accuracies before train start\")\n",
    "    testacc = accuracy(model, x_test, y_test)\n",
    "    trainacc = accuracy(model, x_train, y_train)\n",
    "    println(\"Before training...Accuracies: train: $trainacc test: $testacc\")\n",
    "\n",
    "    info(\"Training started\")\n",
    "    for epoch=1:o[:epochs]\n",
    "        @time for (sequence, ygold) in zip(odata, ygolds)\n",
    "            grads = grugrad(model, state, sequence, ygold)\n",
    "            update!(model, grads, opts)\n",
    "        end\n",
    "        testacc = accuracy(model, x_test, y_test)\n",
    "        trainacc = accuracy(model, x_train, y_train)\n",
    "        println(\"Epoch: $epoch Loss: $lval Train acc: $trainacc Test acc: $testacc\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.1",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
